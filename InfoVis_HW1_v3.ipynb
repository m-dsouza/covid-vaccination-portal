{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InfoVis_HW1_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-dsouza/covid-vaccination-portal/blob/main/InfoVis_HW1_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlI2jBjavHGi"
      },
      "source": [
        "# CS-GY 6313/CUSP-GX 6006 Information Assignment 1\n",
        "\n",
        "Given: Two triangle positions in 3D, triangle colors, and camera parameters. \n",
        "\n",
        "Output: Saved and visualizable color images from the three given cameras (as .png, .jpg, etc.)\n",
        "\n",
        "##Inputs:\n",
        "\n",
        "3D Coordinates of the vertices two triangles (vertices1, vertices2, vertices3)\n",
        "\n",
        "```\n",
        "tri1_vertices = [(x0, y0, z0), (x1, y1, z1), (x2, y2, z2)]\n",
        "tri2_vertices = [(x0, y0, z0), (x1, y1, z1), (x2, y2, z2)] \n",
        "```\n",
        "Camera parameters (position, forward/facing direction, up/camera orientation, fov). Assume aspect ratio is 1:1 and FOV in degrees.\n",
        "```\n",
        "cam1 = [(x0, y0, z0), (x0_f, y0_f, z0_f), (x0_u, y0_u, z0_u), fov0]\n",
        "cam2 = [(x1, y1, z1), (x1_f, y1_f, z1_f), (x1_u, y1_u, z1_u), fov1]\n",
        "cam3 = [(x2, y2, z2), (x2_f, y2_f, z2_f), (x2_u, y2_u, z2_u), fov2]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emnvsFnK0HrV"
      },
      "source": [
        "Changelog: \n",
        "\n",
        "9/29: Fixed a variable typo in scale_by_2_matrix to 2/(t-b), orginally 2/(l-b) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feAxAcPB8EGY"
      },
      "source": [
        "# Programming exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKN9s6seT7go",
        "outputId": "8d5f5bfa-ad7c-4fff-b417-91dbeb0c3491"
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0is-PcpgqiTB"
      },
      "source": [
        "## Render triangles in camera using CPU-only rasterisation.\n",
        "\n",
        "\n",
        "Write a function to render an image using camera settings and triangle vertices as the input. Write your own code for rasterization to render a triangle pixel-by-pixel. You can use any method to show the triangles (ex. Matplotlib, OpenCV, plotly, etc.) as long as you first perform Model-View-Projection.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuYMC1k0_WIV"
      },
      "source": [
        "# Complete the functions for Model View Projection\n",
        "\n",
        "Model: objects to coordinates in world space\n",
        "\n",
        "View: from world space to camera space\n",
        "\n",
        "Projection: from camera space to clip/screen space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef9lWGNpUECT"
      },
      "source": [
        "# Since our triangle vertices are already in world space (x, y, z), there's\n",
        "# no need write a function for the Model part of MVP! We can jump directly to \n",
        "# getting the view matrix and using that to get the camera coordinates."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2P1oZUQCek6"
      },
      "source": [
        "def view(camera, triangle1, triangle2):\n",
        "  ### TODO: Find R_view and T_view using the camera settings\n",
        "\n",
        "  M_view = np.matmul(R_view, T_view)\n",
        "  ### TODO: Use M_view to find the verticees coordinates in camera space\n",
        "\n",
        "  tri1_in_camera_space = [(0, 0, 0), (0, 0, 0), (0, 0, 0)] # Find\n",
        "  tri2_in_camera_space = [(0, 0, 0), (0, 0, 0), (0, 0, 0)] # Find\n",
        "  return tri1_in_camera_space, tri2_in_camera_space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f-N-aOjOkKF"
      },
      "source": [
        "def get_M_persp(field_of_view):\n",
        "  aspect_ratio = 1\n",
        "  ### TODO: Define r, l, b, t, n, and f. Return M_persp\n",
        "  r = 0\n",
        "  l = 0\n",
        "  b = 0\n",
        "  t = 0\n",
        "  n = 0 # You can choose some very small number\n",
        "  f = 0 # You can choose some very large number\n",
        "\n",
        "  scale_by_2 = [[2/(r-l), 0, 0, 0], \n",
        "               [0, 2/(t-b), 0 , 0],\n",
        "               [0, 0, 2/(n-f), 0],\n",
        "               [0, 0, 0, 1]]\n",
        "\n",
        "  translate_center_to_origin = [[1, 0, 0, -(r+l)/2],\n",
        "                                [0, 1, 0, -(t+b)/2],\n",
        "                                [0, 0, 1, -(n+f)/2],\n",
        "                                [0, 0, 1, 0]]\n",
        "\n",
        "  M_ortho = np.matmul(scale_by_2, translate_center_to_origin)\n",
        "\n",
        "  ### TODO: Find M_persp\n",
        "  M_persp = [[],\n",
        "             [],\n",
        "             [],\n",
        "             []]\n",
        "\n",
        "  return M_persp\n",
        "\n",
        "def perspective_projection(field_of_view, tri1, tri2):\n",
        "  M_persp = get_M_persp(field_of_view)\n",
        "  ### TODO: Use M_persp to find the verticees coordinates in camera space\n",
        "  \n",
        "  tri_1_screen_coordinates = [(0, 0), (0, 0), (0, 0)] \n",
        "  tri_2_screen_coordinates = [(0, 0), (0, 0), (0, 0)] \n",
        "  return tri_1_screen_coordinates, tri2_screen_coordinates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL4_6FfBU9ch"
      },
      "source": [
        "def mvp(camera, triangle1, triangle2):\n",
        "  tri1_in_camera_space, tri2_in_camera_space = view(camera)\n",
        "  tri1_in_screen_space, tri2_in_screen_space = perspective_projection(camera[3], tri1_in_camera_space, tri2_in_camera_space)\n",
        "  return tri1_in_screen_space, tri2_in_screen_space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccsB4smnKXsq"
      },
      "source": [
        "def rasterize(tri1, tri2):\n",
        "  pixels = np.zeros(shape = (100, 100, 3)) # 100x100 matrix of RGB values \n",
        "  \n",
        "  # The matrix format is [row][col], or [y][x], so color the pixels accordingly.\n",
        "  ### TODO: Draw the triangles\n",
        "\n",
        "  return pixels\n",
        "\n",
        "### TODO: Write a function for Supersampling (call after image is rasterized)\n",
        "def anti_aliasing(pixels):\n",
        "  return pixels\n",
        "\n",
        "### TODO: Complete the Z_buffer algorithm for occlusion\n",
        "def z_buffer(pixels):\n",
        "  return pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcSoDVNiNyKo"
      },
      "source": [
        "# Triangle vertices in 3D world space\n",
        "tri1 = [(0, 0, 0), (0, 30, 0), (35, 0, 35)] # RGB(255, 0, 0), Red\n",
        "tri2 = [(17, 0, 0), (0, 0, 17), (17, 45, 17)] # RGB(0, 255, 0), Green\n",
        "\n",
        "# cam = [(x, y, z), (x_f, y_f, z_f), (x_u, y_u, z_u), fov]\n",
        "# The first coordinate is where the camera is in world space. The second is what\n",
        "# coordinate it is looking at/facing. The third represents the \"up\" axis.  \n",
        "# Ex. cam1, cam3 up = positive of y-axis. cam2 up = negative if y-axis (upside-down camera)\n",
        "cam1 = [(50, 10, 0), (0, 10, 0), (0, 1, 0), 90] \n",
        "cam2 = [(50, 10, 0), (0, 10, 0), (0, -1, 0), 105]\n",
        "cam3 = [(0, 10, 60), (0, 10, 0), (0, 1, 0), 120] \n",
        "\n",
        "perspective1_tri1, perspective1_tri2 = mvp(cam1, tri1, tri2)\n",
        "perspective2_tri1, perspective2_tri2 = mvp(cam2, tri1, tri2)\n",
        "perspective3_tri1, perspective3_tri2 = mvp(cam3, tri1, tri2)\n",
        "\n",
        "# Draw triangles in 2D\n",
        "rasterize(perspective1_tri1, perspective1_tri2) \n",
        "rasterize(perspective2_tri1, perspective2_tri2)\n",
        "rasterize(perspective3_tri1, perspective3_tri2)\n",
        "\n",
        "### TODO: antialiasing and occlusion\n",
        "\n",
        "# Replace with finished 100x100 matrix (row, column = y, x of pixels)\n",
        "perspective1 = np.zeros(shape = (100, 100, 3)) \n",
        "perspective2 = np.zeros(shape = (100, 100, 3))\n",
        "perspective3 = np.zeros(shape = (100, 100, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd83bOtWNvwP"
      },
      "source": [
        "\n",
        "Save the 100x100x3 RGB images you rendered with the given camera settings and triangle vertices. Images can be displayed using MatplotLib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBzYg5RNhs8P"
      },
      "source": [
        "# Save and view images\n",
        "# origin = \"lower\" sets origin of plot to bottom left\n",
        "plt.imshow(perspective1, origin=\"lower\") \n",
        "plt.show()\n",
        "plt.savefig('perspective1.png')\n",
        "files.download(\"perspective1.png\") \n",
        "plt.imshow(perspective2, origin=\"lower\") \n",
        "plt.show()\n",
        "plt.savefig('perspective2.png')\n",
        "files.download(\"perspective2.png\") \n",
        "plt.imshow(perspective3, origin=\"lower\") \n",
        "plt.show()\n",
        "plt.savefig('perspective3.png')\n",
        "files.download(\"perspective3.png\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "2Eph04MbKiTD",
        "outputId": "85262f18-e726-4bdb-a259-caf5d7ec3f7a"
      },
      "source": [
        "# Example of how to plot an image with a red line at X = 49.\n",
        "# Note that row = y, column = x value of pixel\n",
        "example_image = np.zeros(shape = (100, 100, 3))\n",
        "for row in range(100):\n",
        "  example_image[row][49] = [255, 0, 0]\n",
        "  example_image[row][52] = [0, 255, 0]\n",
        "plt.imshow(example_image, origin=\"lower\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZVUgX39zZZh"
      },
      "source": [
        "# Submission details\n",
        "\n",
        "Click \"File\" > \"Save a Copy in Drive\" and rename the file to your netID followed by \"_InfoVisHW1.\" Ex. \"bsl334_InfoVisHW1.ipynb\"\n",
        "\n",
        "You will be submitting your Colab notebook along with your three camera perspective images. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCZzYBuQ4NSC"
      },
      "source": [
        "Grading\n",
        "\n",
        "```\n",
        "Single triangle with MVP (50%)\n",
        "Single triangle with MVP and anti-aliasing (75%)\n",
        "Two triangles with MVP, anti-aliasing, and occlusion (100%) \n",
        "```"
      ]
    }
  ]
}